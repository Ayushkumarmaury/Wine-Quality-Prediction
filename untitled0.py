# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14UU-_WVYxZi34StnZQ5S1caS0dFAAN1_
"""

# importing dependencies
import pandas as pd;
import numpy as np;
import matplotlib.pyplot as plt;
import seaborn as sns;
from sklearn.model_selection import train_test_split;
from sklearn.ensemble import RandomForestClassifier;
from sklearn.metrics import accuracy_score;

# data collection
wine_dataset = pd.read_csv('/content/winequality-red.csv');

wine_dataset.shape

wine_dataset.head()

# checking missing values
wine_dataset.isnull().sum()

# data analysis and visualization
wine_dataset.describe()

# number of wine for each quality
sns.catplot(x='quality', data=wine_dataset, kind='count',color='green',hue='quality');

# valatile acidity vs quality
plot = plt.figure(figsize=(5,5));
sns.barplot(x='quality', y='volatile acidity', data=wine_dataset, color="green");
plt.show();

# citric acid vs quality
plot = plt.figure(figsize=(5,5));
sns.barplot(x='quality', y='citric acid', data=wine_dataset, color="blue" );
plt.show();

#alcohol vs Quality
plot = plt.figure(figsize=(5,5));
sns.barplot(x='quality', y='alcohol', data=wine_dataset, color="red");
plt.show();

#pH vs Quality
plot = plt.figure(figsize=(5,5));
sns.barplot(x='quality', y='pH', data=wine_dataset, color="brown");
plt.show();

# corelation
correlation = wine_dataset.corr()

# constructing a heatmap to understand the correlation between columns
plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.2f', annot=True, annot_kws={'size':8}, cmap='Greens')

# data preprocessing
x = wine_dataset.drop('quality', axis=1)
print(x)

# label binarization
y= wine_dataset['quality'].apply(lambda y_value: 1 if y_value>=7 else 0)
print(y)

# training and test data
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3)
print(y_train)

print(y.shape, y_train.shape, y_test.shape)

# Modal training using random forest classifier
model = RandomForestClassifier()
model.fit(x_train, y_train)

# model evaluation
# accuracy on test data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction, y_test)
print('Accuracy : ', test_data_accuracy)

# got accuracy of 93%

# building predictive system
input_data =(7.5,0.5,0.36,6.1,0.071,17.0,102.0,0.9978,3.35,0.8,10.5)

# changing input data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the data as we are predicting the label for only one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]==1):
  print('Good Quality Wine ğŸ·ğŸ·ğŸ·!!!')
else:
  print('Bad Quality Wine ğŸ‘.')